{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lec3. 선형 회귀 평가함수 알고리즘 \n",
    "- $ H(x) = Wx+b$,\n",
    "- $cost(W) = \\frac{1}{2m} \\sum_{i=1}^{m} (W(x_i) - y_i )^2$\n",
    "    - $1 \\over 2m$인 건 미문할때 깔끔하려고\n",
    "\n",
    "\n",
    "예를 들면 ((1,1),(2,2),(3,3)) 이면 W,b = 1,0 이면 cost(W) = 0\n",
    "\n",
    "## Gradient dessent algorithm (경사강하법)\n",
    "- 기울기에 따라 값을 감소시키며 계산한다.\n",
    "- 약간 newtown method 같당\n",
    "- $W := W - \\alpha \\frac{\\partial}{\\partial W} cost(W)$\n",
    "    - 여기서 $\\alpa$가 아까 그 0.1\n",
    "- 오목한 모형인지 생각해보기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image.png\n",
    "image.png\n",
    "image.png\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
